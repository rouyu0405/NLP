{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAT-ExploringAI-2024/NLP-with-RNN-and-LLMs/blob/main/GPT_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coEmbIH4m-Ta"
      },
      "source": [
        "## Experimenting with OpenAI GPT\n",
        "\n",
        "This notebook is part of [AI for Beginners Curriculum](http://aka.ms/ai-beginners).\n",
        "\n",
        "In this notebook, we will explore how we can play with OpenAI-GPT model using Hugging Face `transformers` library.\n",
        "\n",
        "Without further ado, let's instantiate text generating pipeline and start generating!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "NVPCGCt8m-Td",
        "outputId": "1f19bce9-6cc5-449b-e409-0cddd1e9d9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "725cd33c80a64fd68bc53089810f4860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/479M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dee640bb7a9459682401997f569b87f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c212e0c98db3444c9fd54a5a9ada45d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5eea981237e440c59cc15fd8f08a3070"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/816k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "920c77b91e1a47be9df05a8368a133cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/458k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7eb0ba3ca4d46e59f3cb3d14d1b5c4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f47460dc2e404d50a9b30cd4f38d09b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Hello! I am a neural network, and I want to say that i miss you guys so much. if you guys didn\\'t know i miss you, just tell me now and i \\'ll leave you alone and i \\'ll forget all about you. \" \\n the message ended without a response. \\n \" thank you for having me again, \" nisha said. \\n chapter 29 \\n as evening approached, nisha sent tweets to her friends, twitter, and the people that tweeted them on their facebook page'},\n",
              " {'generated_text': 'Hello! I am a neural network, and I want to say that my name is althea. i\\'m from the bioengineering lab at the biosciences center of the u. s. international airport in tokyo. and please hold. \" \\n after a heavy pause, john\\'s voice answered. \" thank you, john. this is dr. dr. paul brenner, chief geneticist for dr. ross - ross - ross, at the biosciences center of tokyo, tokyo, japan. i\\'m the head of'},\n",
              " {'generated_text': 'Hello! I am a neural network, and I want to say that i don\\'t think you\\'ve experienced many problems, but you need me to take your pulse. would you like that? \" \\n \" no, if it would help... \" \\n \" good. now you\\'re free to go. \" \\n \" i really need to talk to you. \" \\n \" sure, and i\\'m sure you both are really hungry. i just hope you \\'ll take a minute to eat something and eat something'},\n",
              " {'generated_text': 'Hello! I am a neural network, and I want to say that i have been sent here a little over two, three months ago. this is my ship, the apocalypse, the first vessel to arrive to this world for almost 15, 000 years, with three moons orbiting it and many worlds scattered throughout the galaxy. this is my home planet in the planet, and my home and ship are the only home planet within the galaxy. i have been sent here, to a world that is about to'},\n",
              " {'generated_text': 'Hello! I am a neural network, and I want to say that you will find, if we are able to work around that level before the whole system is completely decimated... \\n... and i want to say, that i would rather use my entire brain to work at your level, but i am only able to bring up my entire brain, all at the same speed. \" \\n \" i already told you that that\\'s against the law. \" \\n \" i am a mind - reader, and'}]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name = 'openai-gpt'\n",
        "\n",
        "generator = pipeline('text-generation', model=model_name)\n",
        "\n",
        "generator(\"Hello! I am a neural network, and I want to say that\", max_length=100, num_return_sequences=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unf2ENzrm-Tf"
      },
      "source": [
        "## Prompt Engineering\n",
        "\n",
        "In some of the problems, you can use openai-gpt generation right away by designing correct prompts. Have a look at the examples below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-QUgH9rm-Tg",
        "outputId": "f81972d2-6dfc-4aac-ef4d-66777c163a0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Synonyms of a word cat: it's very strong and extremely vicious. as the cat is\"},\n",
              " {'generated_text': 'Synonyms of a word cat: a \" cat \" : just a simple word. \\n i'},\n",
              " {'generated_text': 'Synonyms of a word cat: \" and i was told by your grandfather that a cat is'},\n",
              " {'generated_text': 'Synonyms of a word cat: a man who used the word human. not just a cat'},\n",
              " {'generated_text': 'Synonyms of a word cat: the one with the white nose and the white eyebrows. the'}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "generator(\"Synonyms of a word cat:\", max_length=20, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fH5bURhm-Th",
        "outputId": "1053e799-2ee8-46ae-f7ff-72b1424b6827"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive this is so horrible - > positive that your brother is gay - >'},\n",
              " {'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> negative i will bring this on you -, < positive am i, i'},\n",
              " {'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> negative i have self - esteem i must take it - : \\n - -'},\n",
              " {'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> negative this is - : \\n if it were true that the devil would have'},\n",
              " {'generated_text': \"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive i have you - > positive it's a bad thing, > positive\"}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator(\"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this ->\", max_length=40, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZK3IBKBbm-Ti",
        "outputId": "d72dd59c-212f-48f4-b36d-533ca24959c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'Translate English to French: cat => chat, dog => chien, student =>  new and unusual. there were no more words to be'},\n",
              " {'generated_text': 'Translate English to French: cat => chat, dog => chien, student =>  student \\n his eyes were huge in his lean face as'},\n",
              " {'generated_text': \"Translate English to French: cat => chat, dog => chien, student =>  the teacher's words, their words, their words.\"}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator(\"Translate English to French: cat => chat, dog => chien, student => \", top_k=50, max_length=30, num_return_sequences=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhNWlDl4m-Tj",
        "outputId": "c5a676c2-c8a1-4c59-af38-1564e8855b57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'People who liked the movie The Matrix also liked  it, and there was the movie of the first man after us. \\n i wanted to laugh at how stupid these stupid actors were. no, they were'},\n",
              " {'generated_text': \"People who liked the movie The Matrix also liked  the movie, and the film was the result. and that's when the man in the story was brought into reality, after a few decades. \\n a\"},\n",
              " {'generated_text': 'People who liked the movie The Matrix also liked  the movie the matrix, because there was a very old movie movie called the matrix, where there was a great super hero, and the super hero came out'},\n",
              " {'generated_text': \"People who liked the movie The Matrix also liked  the movie that didn't have a chance to pay cash, if they could afford it. most often they got a good deal and a lot of money,\"},\n",
              " {'generated_text': \"People who liked the movie The Matrix also liked  the movie, and i didn't seem to have the same problem. \\n i 'd met the other half of my family. i spent most of my time\"}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator(\"People who liked the movie The Matrix also liked \", max_length=40, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHDrm0FMm-Tk"
      },
      "source": [
        "## Text Sampling Strategies\n",
        "\n",
        "So far we have been using simple **greedy** sampling strategy, when we selected next word based on the highest probability. Here is how it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGjyMZN8m-Tl",
        "outputId": "9c7a955b-131c-426e-90dd-fc65fc30fc61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw that it was the kitchen area. an impressive piece of work. my father, a former fbi agent, had a massive collection of computers, laptops, and a slew of books that read a lot like history. i don't tell you how much his collection meant to me. he and my mother spent their free time on their laptop, reading\"},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw my girlfriend\\'s face. i stood there for a minute, still with my heart pounding like crazy. the look she had was both sexy and sad. she looked like she had aged a lifetime, and i hated that i had kept her in the dark as long as i had. \\n \" hey. \" \\n \" hey, \" i said'},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw that mrs. givens and julie were alone. so i went and sat down and didn\\'t say a word. after a while mrs. givens came over. \" what\\'s happened to you and julie? julie always has a little smile on her face. \" i said. \" do you need a shoulder to cry on? \" she took me by the'},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw it was in an uproar. i\\'m not sure why we would need to see the mess, but i guess we did. \\n \" mrs. muller, you\\'re fired! \" \\n she was stunned by my revelation at first. she was a little startled, and then she realized that the damage had been done. she looked back and forth between'},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw my old friend, david. we\\'ve known each other for longer than i can remember. i can\\'t remember exactly when he and i met. he had a different time frame in mind, but it was one of the reasons i left for chicago. i needed to be able to give him the right answers before he took this trip. \"'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
        "generator(prompt,max_length=100,num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNZHdHVrm-Tm"
      },
      "source": [
        "**Beam Search** allows the generator to explore several directions (*beams*) of text generation, and select the ones with highers overall score. You can do beam search by providing `num_beams` parameter. You can also specify `no_repeat_ngram_size` to penalize the model for repeating n-grams of a given size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8PHpe7hm-Tn",
        "outputId": "5d553147-46dc-4255-eda4-fffaff0cbc20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he looked up at me and smiled. \\n \" hi, \" he said. \" i\\'m sorry to bother you. what can i do for you? \" \\n i didn\\'t know what to say so i just sat down in the chair across from him and asked him what he wanted.'},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he looked up at me and smiled. \\n \" hi, \" he said. \" i\\'m sorry to bother you. what can i do for you? \" \\n i didn\\'t know what to say so i just sat down in the chair across from him and asked him what he was doing'},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he looked up at me and smiled. \\n \" hi, \" he said. \" i\\'m sorry to bother you. what can i do for you? \" \\n i didn\\'t know what to say so i just sat down in the chair across from him and asked him what he wanted to'},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he looked up at me and smiled. \\n \" hi, \" he said. \" i\\'m sorry to bother you. what can i do for you? \" \\n i didn\\'t know what to say so i just sat down in the chair across from his bed and stared at him. his'},\n",
              " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he looked up at me and smiled. \\n \" hi, \" he said. \" i\\'m sorry to bother you. what can i do for you? \" \\n i didn\\'t know what to say so i just sat down in the chair across from his bed and stared at him. the'}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
        "generator(prompt,max_length=100,num_return_sequences=5,num_beams=10,no_repeat_ngram_size=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrEOt3qDm-To"
      },
      "source": [
        "**Sampling** selects the next word non-deterministically, using the probability distribution returned by the model. You turn on sampling using `do_sample=True` parameter. You can also specify `temperature`, to make the model more or less deterministic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw9WQKDBm-To",
        "outputId": "23bc1fd1-8876-4f8c-b41e-a9cc79827c70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw her. she was on the bed, but she looked very different. \\n \" honey, what\\'s the matter? \" i asked. \\n she sat up. \" i can\\'t believe it\\'s real. i\\'ve been dreaming about you for the last two days. \" \\n \" i can\\'t believe it either. i guess that\\'s how'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
        "generator(prompt,max_length=100,do_sample=True,temperature=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ5f6vmbm-Tp"
      },
      "source": [
        "We can also provide to additional parameters to sampling:\n",
        "* `top_k` specifies the number of word options to consider when using sampling. This minimizes the chance of getting weird (low-probability) words in our text.\n",
        "* `top_p` is similar, but we chose the smallest subset of most probable words, whose total probability is larger than p.\n",
        "\n",
        "Feel free to experiment with adding those parameters in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Ld2X-Zm-Tp"
      },
      "source": [
        "## Fine-Tuning your models\n",
        "\n",
        "You can also [fine-tune your model](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/fine-tuning?pivots=programming-language-studio?WT.mc_id=academic-77998-bethanycheum) on your own dataset. This will allow you to adjust the style of text, while keeping the major part of language model."
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "16af2a8bbb083ea23e5e41c7f5787656b2ce26968575d8763f2c4b17f9cd711f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('py38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
